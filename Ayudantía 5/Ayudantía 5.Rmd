---
title: "Ayudantía 5 - ML para Negocios"
date: "21 de septiembre del 2022"
output:
  rmdformats::downcute:
    self_contained: true
    default_style: "dark"
    downcute_theme: "default"
---

```{=html}
<style type="text/css">
body{
  font-size: 15pt;
}
.Wrap {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>
```

```{r setup, include=FALSE, message=FALSE}
library(here)


## Global options
knitr::opts_chunk$set(cache = TRUE, fig.align = 'center')

# Here
here::i_am('Ayudantía 5/Ayudantía 5.Rmd')
```

# Introducción

Bienvenid\@s a la quinta ayudantía de EAA3707 - Machine Learning para Negocios. En la ayudantía veremos:

1.  K-Nearest Neighbors
2.  Aplicación en regresión
3.  Elección del número de vecinos
3.  Discusión: Curse of dimensionality

Antes de comenzar, cargamos las librerías que utilizaremos durante la ayudantía.

```{r librerias, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)


# Para obtener resultados reproducibles
set.seed(912)
```

Les recuerdo los libros que les recomiendo para aprender de R:

-   **Hands-On Programming with R**: disponible [acá](https://rstudio-education.github.io/hopr/). Útil para recordar cosas básicas de R.

-   **Advanced R**: disponible [acá](https://adv-r.hadley.nz/). Para aprender R avanzado (realmente avanzado), si es que están interesados en entender cómo funciona R por detrás.

-   **R for Data Science**: disponible [acá](https://r4ds.had.co.nz/). Bueno para aprender y aplicar Data Science de manera rápida, además de ser uno de los libros guía para aprender acerca de los paquetes de tidyverse.

-   **RMarkdown Cookbook**: disponible [acá](https://bookdown.org/yihui/rmarkdown-cookbook/). Útil para aprender lo básico de RMarkdown.

-   **RMarkdown: The Definitive Guide**: disponible [acá](https://bookdown.org/yihui/rmarkdown/). Útil para aprender cosas avanzadas de RMarkdown.

-   **Tidy Modeling with R**: disponible [acá](https://www.tmwr.org/). Recomendado para aprender del ecosistema tidymodels. Tiene también un capítulo pequeño de tidyverse con lo justo y necesario.

# Algoritmo K-vecinos cercanos (KNN)

<center>![Algoritmo K-vecinos cercanos](https://www.jcchouinard.com/wp-content/uploads/2021/08/image-8.png){height=500px width=750px}</center>

El algoritmo K-vecinos cercanos (KNN) es uno de los algoritmos de aprendizaje supervisado más simples e intuitivos, y el cual puede ser utilizado tanto en el contexto de regresión como en el de clasificación.

Este algoritmo realizará la predicción de acuerdo a un número $k$ de vecinos que se encuentren más cercanos a la observación. En particular, en el contexto de clasificación, tendremos que la observación se asignará a la clase con un mayor número de instancias dentro de estos vecinos, mientras que en el caso de regresión se toma un promedio de las respuestas.

Con lo anterior podemos notar que este método no realiza ningún ajuste por detrás, como lo hace por ejemplo una regresión lineal o logística para obtener estimaciones de los parámetros que definen aquellos modelos.

Acá es **MUY** importante tener siempre en cuenta que este método trabaja con el concepto de distancia entre observaciones. En nuestro caso trabajaremos con distancia euclideana, pero si investigan notaran que existen otras distancias, las que también pueden depender del tipo de dato con el que trabajen (por ejemplo distancias entre palabras)

Considerando lo anterior, si nuestros predictores están en escalas diferentes entonces será necesario estandarizar nuestros datos. Por ejemplo, si queremos comparar casas entre sí y tenemos tanto el precio en pesos como el tamaño en metros cuadrados, entonces las diferencias de precios, que estarán por los millones, dominará completamente la distancia entre observaciones.

# Aplicación - Transacciones de bienes raíces

<center>![](https://www.vmcdn.ca/f/files/kamloopsmatters/images/stock-photos/housing/home-for-sale.jpg;w=960){height=500px width=900px}</center>

En clases ya vieron el uso del algoritmo KNN para el caso que la variable respuesta es categórica, por lo que acá consideraremos el otro caso correspondiente a una variable respuesta numérica.

En particular, si denotamos por $N_k(x)$ el conjunto de las k observaciones más cercanas a x, entonces tenemos que el estimador KNN está dado por:

$$
\hat{Y}(x) = \frac{1}{k}\sum_{x_i \in N_k(x)} y_i
$$

Como una aplicación práctica, utilizaremos la base de datos `Sacramento` la cual contiene información de 932 transacciones de bienes raíces en el condado de Sacramento, California. En particular, nos interesa poder predecir el precio al que se venderá una casa utilizando diferentes atributos como el tamaño de la casa, el número de piezas, el número de baños, etc.

**Nota**: estos datos vienen en la librería `modeldata`, la cual se carga automáticamente al cargar la librería `tidymodels`. Para más información de la base de datos, pueden utilizar `?Sacramento`.

Para simplificar el análisis y poder visualizar de mejor manera los resultados utilizaremos solo la variable `sqft` para poder predecir el precio. La extensión del algoritmo al caso multivariado es directo, aunque hay que tener cuidado con respecto a las diferencias de magnitudes entre variables, así como el tipo de variable.

## Análisis exploratorio

Dado que nos interesa predecir el precio, veamos en primer lugar cómo distribuye esta variable.

```{r ae - precio, echo=FALSE}
ggplot(Sacramento, aes(x = price)) +
  geom_histogram(aes(y = ..density..), bins = 30, col = 'black', fill = 'salmon') +
  geom_density(col = 'blue', lwd = 2) +
  scale_x_continuous(labels = dollar_format()) +
  theme(text = element_text(size = 12)) +
  labs(title = 'Distribución del precio de las casas',
       subtitle = 'Condado de Sacramento, California',
       x = 'Precio (Dólares)', y = 'Densidad')
```

Por otro lado, considerando que nos interesa poder predecir el precio de venta a partir del tamaño en metros cuadrados de la casa, graficamos ambas variables en la misma figura.

```{r ae - relacion sqft y precio, echo=FALSE}
ggplot(Sacramento, aes(x = sqft, y = price)) +
  geom_point() +
  theme(text = element_text(size = 12)) + 
  scale_y_continuous(labels = dollar_format()) +
  labs(title = 'Relación tamaño y precio',
       subtitle = 'Condado de Sacramento, California',
       x = 'Tamaño', y = 'Precio (Dólares)')
```

Notamos que efectivamente a medida que el tamaño de la casa aumenta entonces el precio también tiende a aumentar.



